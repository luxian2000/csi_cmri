{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1afe5f8-6d3c-4036-884c-8d92447a1c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ffe7a72-cdda-4afa-af93-5e0a21f9c627",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aeaf3af-6d2b-4650-99d3-207d42b8666d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "data = np.load('../DataSpace/csi_cmri/CSI_channel_30km.npy')  # shape=(80000, 2560)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "824b2409-01e5-4193-8929-4fca3b1a8127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据划分参数\n",
    "TOTAL_SAMPLES = 80000\n",
    "TRAIN_RATIO = 0.70    # 70% 训练\n",
    "VAL_RATIO = 0.15      # 15% 验证  \n",
    "TEST_RATIO = 0.15     # 15% 测试\n",
    "\n",
    "# 设置量子线路参数\n",
    "INPUT_DIM = data.shape[1]\n",
    "OUTPUT_DIM = 256\n",
    "ALL_QUBITS = int(np.ceil(np.log2(INPUT_DIM))) + 1\n",
    "TAR_QUBITS = int(np.ceil(np.log2(OUTPUT_DIM))) + 1\n",
    "ANS_QUBITS = TAR_QUBITS - ALL_QUBITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f108a21-7f01-4bec-b6d7-0024cc16d6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHT = torch.randn(INPUT_DIM, OUTPUT_DIM, requires_grad=True) * 0.1\n",
    "BIAS = torch.randn(1, OUTPUT_DIM, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1adeeef5-6072-4fba-bd4e-e948b424cd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + torch.exp(-x))\n",
    "\n",
    "def normlize(x):\n",
    "    norm = torch.norm(x)\n",
    "    if norm == 0:\n",
    "        return x\n",
    "    return x / norm\n",
    "\n",
    "def dense_layer(x, c_weight, c_bias):\n",
    "    if isinstance(x, np.ndarray):\n",
    "        x = torch.from_numpy(x).float()\n",
    "    output = torch.matmul(x, c_weight) + c_bias\n",
    "    output = sigmoid(output)\n",
    "    output = normlize(output[0])  # 确保输出是一维的\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb0f6d94-f50e-4b97-8660-c35c0c1a236f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FRQI编码量子线路\n",
    "def frqi_encoder(qubits, params, target_wire=0):\n",
    "    # 对数据量子比特应用Hadamard门创建叠加态\n",
    "    for i in range(1, qubits + 1):\n",
    "        qml.Hadamard(wires=i)\n",
    "    # 使用受控PauliY旋转进行编码\n",
    "    for index in range(min(2**qubits, len(params))):\n",
    "        binary_str = bin(index)[2:].zfill(qubits)\n",
    "        bits = [int(bit) for bit in binary_str]\n",
    "        bits.reverse()\n",
    "        qml.ctrl(qml.RY, control=range(1, qubits + 1), control_values=bits)(params[index], wires=target_wire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6f5481-e58c-47d6-969d-35bdcffc387e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "681e21e5-7f00-4a10-9a21-43e6ba72025b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=ALL_QUBITS)\n",
    "@qml.qnode(dev, interface = \"torch\")\n",
    "def cir(sample, c_weight, c_bias, q_weight=0):\n",
    "    y = dense_layer(sample, c_weight, c_bias)\n",
    "    frqi_encoder(qubits=TAR_QUBITS, params=y) \n",
    "    return qml.expval(qml.PauliZ(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e812ba5c-7902-4193-93eb-104a3533fce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = torch.randn(INPUT_DIM, requires_grad=True)\n",
    "loss = cir(tmp, WEIGHT, BIAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06055e33-72bf-487a-b07c-516a71726a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "991b54a5-383c-4ed0-89eb-b495fac93451",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/57/4l0h95jd5kd2qc52xw3xpm000000gn/T/ipykernel_2928/1738442998.py:1: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/core/TensorBody.h:494.)\n",
      "  WEIGHT.grad\n"
     ]
    }
   ],
   "source": [
    "WEIGHT.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "badf7346-1764-4dbe-aef7-cb6be7ec8618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3858e-10, -8.2269e-10, -2.2214e-09, -3.3971e-11, -1.7184e-09,\n",
       "         -1.0032e-09,  4.2159e-11, -2.3557e-09,  8.9281e-11, -3.2191e-11,\n",
       "          1.8870e-11, -2.7728e-09,  6.4596e-11, -9.0416e-10, -6.1472e-10,\n",
       "         -1.1788e-10, -1.6794e-09,  3.0393e-11,  1.6394e-11, -8.3682e-12,\n",
       "         -7.8503e-10, -5.1230e-10, -1.5925e-09, -2.4481e-10, -2.0849e-09,\n",
       "         -1.2100e-09, -2.2380e-10, -1.7877e-10, -1.9789e-09,  2.3006e-11,\n",
       "         -2.8690e-09, -1.0512e-10,  1.0315e-11, -2.1656e-09, -1.6233e-09,\n",
       "         -1.0270e-12, -4.6225e-10, -1.0252e-10, -3.6693e-09, -4.8994e-14,\n",
       "          3.8422e-11, -2.6797e-11, -3.2205e-10, -5.4081e-13, -2.1934e-09,\n",
       "         -2.4434e-09, -4.3952e-10, -2.8156e-10, -1.9377e-09, -2.3177e-09,\n",
       "          2.5279e-11, -1.3944e-10, -1.8969e-09, -2.7499e-09, -6.7641e-10,\n",
       "         -7.6506e-10, -2.0893e-10, -3.8149e-10,  3.8328e-12, -2.5917e-11,\n",
       "          2.0655e-13, -2.3907e-09, -1.9911e-09,  5.7187e-11, -1.1718e-11,\n",
       "         -2.2713e-10, -8.9967e-11, -2.3866e-09, -2.0960e-09, -7.7200e-10,\n",
       "         -3.4924e-10,  5.6811e-12, -6.3641e-10, -1.6408e-10, -2.4088e-09,\n",
       "          9.8573e-13, -9.6356e-10,  2.3915e-11, -2.3974e-09,  2.3649e-13,\n",
       "         -1.8399e-09,  5.8332e-11, -6.6947e-15, -2.1180e-10,  2.6157e-12,\n",
       "          7.9581e-12,  1.8883e-11, -2.3067e-09, -1.5111e-09, -9.2834e-11,\n",
       "         -7.5671e-10,  6.0024e-11, -3.1402e-11,  1.0921e-10,  3.9754e-11,\n",
       "          6.5010e-11, -1.2232e-09, -2.5820e-10, -2.1445e-09,  3.9874e-11,\n",
       "         -9.8573e-10,  6.8013e-11,  2.4424e-11,  1.0857e-10,  9.7069e-12,\n",
       "          5.3761e-11, -2.1865e-10, -2.6464e-12, -2.2743e-09, -2.3887e-09,\n",
       "          3.3676e-11,  2.2965e-11,  4.3942e-11, -1.0702e-09, -1.2890e-09,\n",
       "         -1.4478e-09, -2.3993e-09,  5.8021e-11,  6.2258e-11, -7.5237e-10,\n",
       "         -3.1093e-10, -6.9789e-10, -3.6342e-10, -1.6781e-10, -2.7321e-11,\n",
       "          6.7138e-11, -1.5611e-09, -9.9379e-10,  3.4135e-11, -2.0558e-09,\n",
       "         -1.2597e-10, -1.7415e-09, -5.5968e-13,  1.4753e-13, -1.9683e-11,\n",
       "         -2.3677e-09, -8.3774e-10,  4.4194e-12, -1.2824e-11, -5.3052e-10,\n",
       "         -1.9332e-09, -8.8840e-10, -1.9096e-11,  3.5338e-12, -2.1162e-09,\n",
       "         -2.3612e-09,  2.0741e-11, -2.2659e-10, -2.1406e-09, -1.4930e-10,\n",
       "          1.8642e-11, -4.6413e-10, -1.0301e-09, -4.1984e-09, -5.8755e-10,\n",
       "         -5.5500e-11, -9.8281e-11, -2.0491e-10,  1.3407e-12, -4.4857e-09,\n",
       "         -2.3363e-09, -1.2600e-10, -1.6822e-11, -1.3107e-11, -3.6193e-10,\n",
       "         -1.2521e-09, -1.1910e-09, -9.1057e-13, -2.2046e-09,  5.7353e-11,\n",
       "         -2.8265e-11,  1.7221e-11, -3.4999e-09, -2.1330e-09, -2.9470e-13,\n",
       "         -2.8915e-10, -3.0350e-12, -1.4903e-10, -3.1717e-11,  6.9635e-11,\n",
       "          6.3671e-11, -4.4506e-12, -8.4762e-10, -2.4358e-09, -3.9975e-11,\n",
       "         -2.4366e-09, -2.3140e-09, -2.5304e-12, -5.3103e-10, -1.2904e-10,\n",
       "         -4.2068e-09,  3.1392e-12,  3.9971e-11,  2.0436e-11, -4.4103e-09,\n",
       "          2.9951e-11,  2.4038e-11, -8.8391e-11, -2.6902e-10, -1.7745e-09,\n",
       "         -1.2277e-09, -2.3832e-09, -2.4449e-09,  2.5172e-11, -1.0356e-13,\n",
       "         -1.3671e-09, -6.4397e-10,  4.1263e-12, -1.8404e-10, -3.5731e-10,\n",
       "          5.0033e-11, -2.6629e-09,  1.1373e-11,  4.7429e-11, -2.2927e-09,\n",
       "         -2.6991e-09, -1.1903e-09, -1.9232e-11, -2.0048e-09, -1.6344e-10,\n",
       "          2.9537e-11, -2.4200e-09,  2.5336e-11, -7.3268e-11, -3.8447e-10,\n",
       "         -2.6037e-10, -5.3342e-10, -2.2758e-09, -1.0321e-09,  5.1789e-11,\n",
       "          3.9230e-12, -3.6033e-10, -3.7048e-09, -1.4669e-11, -2.1744e-09,\n",
       "         -3.3613e-10,  4.6199e-11, -4.3652e-09, -2.1329e-10,  2.4373e-12,\n",
       "          3.9680e-13, -2.0371e-09,  5.4679e-11, -2.4628e-09,  7.1010e-11,\n",
       "         -3.0160e-10, -1.2831e-09, -2.9001e-10, -7.2664e-10, -7.5382e-10,\n",
       "         -1.3025e-09, -7.2966e-10, -2.7734e-09,  9.6792e-13,  2.1632e-11,\n",
       "         -2.0893e-11]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BIAS.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b05c447-b513-402b-9bfa-572b8fe68c52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:penny] *",
   "language": "python",
   "name": "conda-env-penny-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
